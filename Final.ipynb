{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9MEUeJYdkbx",
        "outputId": "f6c216fa-b2bb-41f6-91a5-b80cf5bd3e8b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UMI0d0adltl",
        "outputId": "082cc3a2-a9cb-4dd1-c184-374cc481dc9a"
      },
      "outputs": [],
      "source": [
        "%cd  PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgr3X8i0dRCM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "from torchvision.datasets import DatasetFolder, ImageFolder\n",
        "from PIL import Image\n",
        "import glob as gb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "2Y_eLPMEdUxx",
        "outputId": "c5ddea68-67c5-4708-83df-caa2ceb3dfb2"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop((256,256)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.5,contrast=0,saturation =0,hue =0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((256,256) ),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = './training'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "image_datasets2 = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms['val']) for x in ['train']}\n",
        "image_datasets['train'] = ConcatDataset([image_datasets['train'],image_datasets2['train']])\n",
        "\n",
        "batch_size = 32\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "print(f\"Using device {device}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i96vlrpddXxq"
      },
      "outputs": [],
      "source": [
        "losses = {'train':[], 'val':[]}\n",
        "accuracies = {'train':[], 'val':[]}\n",
        "lr = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdn5tP7wdZl7"
      },
      "outputs": [],
      "source": [
        "# Resnet50、resnext50_32x4d、googlenet、efficientnet_b4\n",
        "\n",
        "def train_classifier(seed, epochs, model, since):\n",
        "    print('Creating a model {}...'.format(seed))\n",
        "\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if seed==0 or seed==1 or seed==2:\n",
        "      # optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay = 1e-5)\n",
        "      optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)\n",
        "    else:\n",
        "      # optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "      optimizer = optim.SGD(model.classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "      for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "          model.train()\n",
        "        else:\n",
        "          model.eval()\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0.0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders[phase]):\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          with torch.set_grad_enabled(phase=='train'):\n",
        "            outp = model(inputs)\n",
        "            _, pred = torch.max(outp, 1)\n",
        "            loss = criterion(outp, labels)\n",
        "          \n",
        "            if phase == 'train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "          running_loss += loss.item()*inputs.size(0)\n",
        "          running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "        if phase == 'train':\n",
        "            acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
        "            scheduler.step(acc)\n",
        "\n",
        "        epoch_loss = (running_loss / dataset_sizes[phase])\n",
        "        epoch_acc = (running_corrects.double()/dataset_sizes[phase])\n",
        "        losses[phase].append(epoch_loss)\n",
        "        accuracies[phase].append(epoch_acc)\n",
        "        if phase == 'train':\n",
        "          print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "        print('{} - loss:{:.4f}, accuracy: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "        lr.append(scheduler._last_lr)\n",
        "          \n",
        "        if phase == 'val':\n",
        "          print('Time: {}m {:.2f}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
        "          print('=='*31)\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "          best_acc = epoch_acc\n",
        "          best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('CLASSIFIER TRAINING TIME {}m {:.2f}s'.format(time_elapsed//60, time_elapsed%60))\n",
        "    print('=='*31)\n",
        "    print(f'Best Acc of model{seed}: {best_acc}')\n",
        "    return best_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deAUwFdSdaZq"
      },
      "outputs": [],
      "source": [
        "def train_net(seed, epochs, model, since):\n",
        "  model.to(device)\n",
        "  for param in model.parameters():\n",
        "        param.requires_grad=True\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0.0\n",
        "\n",
        "      for inputs, labels in tqdm(dataloaders[phase]):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase=='train'):\n",
        "          outp = model(inputs)\n",
        "          _, pred = torch.max(outp, 1)\n",
        "          loss = criterion(outp, labels)\n",
        "        \n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()*inputs.size(0)\n",
        "        running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "      if phase == 'train':\n",
        "        acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
        "        scheduler.step(acc)\n",
        "\n",
        "      epoch_loss = (running_loss / dataset_sizes[phase])\n",
        "      epoch_acc = (running_corrects.double()/dataset_sizes[phase])\n",
        "      losses[phase].append(epoch_loss)\n",
        "      accuracies[phase].append(epoch_acc)\n",
        "      if phase == 'train':\n",
        "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "      print('{} - loss:{:.4f}, accuracy: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "      lr.append(scheduler._last_lr)\n",
        "    \n",
        "      if phase == 'val':\n",
        "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
        "        print('=='*31)    \n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model = copy.deepcopy(model.state_dict())\n",
        "  time_elapsed = time.time() - since\n",
        "  print('ALL NET TRAINING TIME {}m {:.2f}s'.format(time_elapsed//60, time_elapsed%60))\n",
        "  print('=='*31)\n",
        "  print(f'Best Acc of model{seed}: {best_acc}')\n",
        "\n",
        "  model.load_state_dict(best_model)\n",
        "  torch.save(model.state_dict(), f'./model{seed}.pth')\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxeUM2_2db2x"
      },
      "outputs": [],
      "source": [
        "def train(seed, epochs, model):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model = train_classifier(seed, epochs, model, since)\n",
        "  model.load_state_dict(best_model)\n",
        "  model = train_net(seed, epochs, model, since)\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-CZJ8XGddh3"
      },
      "outputs": [],
      "source": [
        "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "for param in resnet50.parameters():\n",
        "  param.grad_requires = False\n",
        "\n",
        "resnet50.fc = nn.Linear(in_features=resnet50.fc.in_features, out_features=219, bias=True)\n",
        "\n",
        "\n",
        "resnext50_32x4d = torchvision.models.resnext50_32x4d(pretrained=True)\n",
        "for param in resnext50_32x4d.parameters():\n",
        "  param.grad_requires = False\n",
        "\n",
        "resnext50_32x4d.fc = nn.Linear(in_features=resnext50_32x4d.fc.in_features, out_features=219, bias=True)\n",
        "\n",
        "\n",
        "efficientnet_b4 = torchvision.models.efficientnet_b4(pretrained=True)\n",
        "for param in efficientnet_b4.parameters():\n",
        "  param.grad_requires = False\n",
        "\n",
        "efficientnet_b4.classifier[-1] = nn.Linear(in_features=efficientnet_b4.classifier[-1].in_features, out_features=219, bias=True)\n",
        "\n",
        "convnext_base = torchvision.models.convnext_base(pretrained=True)\n",
        "for param in convnext_base.parameters():\n",
        "  param.grad_requires = False\n",
        "\n",
        "convnext_base.classifier[-1] = nn.Linear(in_features=convnext_base.classifier[-1].in_features, out_features=219, bias=True)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "models = [resnet50, resnext50_32x4d, efficientnet_b4, convnext_base]\n",
        "num_models = len(models)\n",
        "\n",
        "for seed in range(num_models):\n",
        "   train(seed=seed, epochs=epochs, model=models[seed])\n",
        "   losses = {'train':[], 'val':[]}\n",
        "   accuracies = {'train':[], 'val':[]}\n",
        "   lr = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSyZSt4WQhAw"
      },
      "outputs": [],
      "source": [
        "class Ensemble1(nn.Module):\n",
        "    def __init__(self, models_list, device):\n",
        "        super(Ensemble1,self).__init__()\n",
        "        self.models = nn.ModuleList(models_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = torch.zeros([x.size(0), 219]).to(device)\n",
        "        for model in self.models:\n",
        "            output += model(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KKFBQfDQkL6"
      },
      "outputs": [],
      "source": [
        "resnet50 = torchvision.models.resnet50()\n",
        "resnet50.fc = nn.Linear(in_features=resnet50.fc.in_features, out_features=219, bias=True)\n",
        "resnet50.load_state_dict(torch.load(f'./ensemble/model0.pth'))\n",
        "\n",
        "resnext50_32x4d = torchvision.models.resnext50_32x4d()\n",
        "resnext50_32x4d.fc = nn.Linear(in_features=resnext50_32x4d.fc.in_features, out_features=219, bias=True)\n",
        "resnext50_32x4d.load_state_dict(torch.load(f'./ensemble/model1.pth'))\n",
        "\n",
        "densenet201 = torchvision.models.densenet201()\n",
        "densenet201.classifier = nn.Linear(in_features=densenet201.classifier.in_features, out_features=219, bias=True)\n",
        "densenet201.load_state_dict(torch.load(f'./ensemble/model3.pth'))\n",
        "\n",
        "convnext_base = torchvision.models.convnext_base()\n",
        "convnext_base.classifier[-1] = nn.Linear(in_features=convnext_base.classifier[-1].in_features, out_features=219, bias=True)\n",
        "convnext_base.load_state_dict(torch.load(f'./ensemble/model4.pth'))\n",
        "\n",
        "\n",
        "models_list = [resnet50, resnext50_32x4d, densenet201, convnext_base]\n",
        "\n",
        "\n",
        "ensemble_model = Ensemble1(models_list, device)\n",
        "ensemble_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cezihDDQPAGI"
      },
      "outputs": [],
      "source": [
        "test_tfm = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "dataset=datasets.ImageFolder('./data/',transforms.Compose([\n",
        "      transforms.Resize((256,256) ),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "  ]),)\n",
        "\n",
        "filename=[]\n",
        "\n",
        "for i in range(len(dataset.imgs)):\n",
        "  y = dataset.imgs[i][0]\n",
        "  y = str(y).replace('./data/train_data/','')\n",
        "  filename.append(y)\n",
        "    \n",
        "test_loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "model = ensemble_model\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "predictions = []\n",
        "for batch in tqdm(test_loader):\n",
        "  imgs, labels = batch\n",
        "  with torch.no_grad():\n",
        "      inputs = imgs.to(device)\n",
        "      logits = model(inputs)\n",
        "  predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
